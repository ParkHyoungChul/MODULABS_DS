{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPXHP8MtTINTW03K0UGASWh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ì‹¤í—˜ ì„¤ëª…\n","\n","ì €ëŠ” ë°ì´í„°ë¥¼ êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ë„£ê³  ì§„í–‰í–ˆìŠµë‹ˆë‹¤\n","\n","ì•„ë˜ ê²½ë¡œë¥¼ ì²´í¬í•´ì„œ ì˜¤ë¥˜ê°€ ë‚˜ì§€ì•Šê²Œ ì¡°ì‹¬í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤\n","\n","## í•™ìŠµ ì†Œìš”ì‹œê°„\n","\n","ì•„ë˜ ëª¨ë¸ ê¸°ì¤€ í•™ìŠµì— 5 epochì— 30ë¶„ì •ë„ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤\n"],"metadata":{"id":"jsXMz5jizDCY"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UftKukFdqA7u","executionInfo":{"status":"ok","timestamp":1765262305854,"user_tz":-540,"elapsed":2783,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}},"outputId":"40ccdfab-ed04-40df-c2cd-6509e75330d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["\n","# ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# ë°ì´í„° load ë° ì••ì¶• í•´ì œ\n","\n","import os\n","import zipfile\n","\n","# ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ - ë¯¸ë¦¬ ë‹¤ìš´ë°›ì•„ë‘” ë°ì´í„°ë¡œ ì‹¤í—˜ ì§„í–‰\n","data_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…¦á„Šá…¡/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼/data'\n","lyrics_path = os.path.join(data_path, 'ì‘ì‚¬ê°€')\n","\n","# ì••ì¶• íŒŒì¼ ëª©ë¡\n","zip_files = {\n","    'lyrics.zip': 'lyrics'\n","}\n","\n","for zip_name, folder_name in zip_files.items():\n","    zip_path = os.path.join(lyrics_path, zip_name)           # zip íŒŒì¼ ì „ì²´ ê²½ë¡œ\n","    extract_dir = os.path.join(lyrics_path, folder_name)     # ì••ì¶• í•´ì œë  í´ë”\n","\n","    # í´ë” ì—†ìœ¼ë©´ ìƒì„±\n","    os.makedirs(extract_dir, exist_ok=True)\n","\n","    print(f\"ğŸ” ì••ì¶• í•´ì œ ì¤‘: {zip_name} â†’ {extract_dir}\")\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_dir)\n","\n","print(\"âœ… ëª¨ë“  ì••ì¶• í•´ì œ ì™„ë£Œ!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Uwx_aEMqHSZ","executionInfo":{"status":"ok","timestamp":1765262307286,"user_tz":-540,"elapsed":1435,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}},"outputId":"fe1d5355-c30a-4a2a-d580-a9bf68cf7fd0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” ì••ì¶• í•´ì œ ì¤‘: lyrics.zip â†’ /content/drive/MyDrive/Colab Notebooks/á„ƒá…¦á„Šá…¡/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼/data/ì‘ì‚¬ê°€/lyrics\n","âœ… ëª¨ë“  ì••ì¶• í•´ì œ ì™„ë£Œ!\n"]}]},{"cell_type":"code","source":["import glob #glob ëª¨ë“ˆì˜ glob í•¨ìˆ˜ëŠ” ì‚¬ìš©ìê°€ ì œì‹œí•œ ì¡°ê±´ì— ë§ëŠ” íŒŒì¼ëª…ì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•œë‹¤\n","import os\n","\n","lyrics_file_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…¦á„Šá…¡/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼/data/á„Œá…¡á†¨á„‰á…¡á„€á…¡/lyrics/lyrics/*'\n","\n","txt_list = glob.glob(lyrics_file_path) #txt_file_path ê²½ë¡œì— ìˆëŠ” ëª¨ë“  íŒŒì¼ëª…ì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ txt_list ì— í• ë‹¹\n"],"metadata":{"id":"wYYbQiTNqy0G","executionInfo":{"status":"ok","timestamp":1765262307302,"user_tz":-540,"elapsed":15,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["raw_corpus = []\n","\n","# ì—¬ëŸ¬ê°œì˜ txt íŒŒì¼ì„ ëª¨ë‘ ì½ì–´ì„œ raw_corpus ì— ë‹´ìŠµë‹ˆë‹¤.\n","for txt_file in txt_list:\n","    with open(txt_file, \"r\") as f:\n","        raw = f.read().splitlines() #read() : íŒŒì¼ ì „ì²´ì˜ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì½ì–´ì˜¨ë‹¤. , splitlines()  : ì—¬ëŸ¬ë¼ì¸ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ ìˆëŠ” ë¬¸ìì—´ì„ í•œë¼ì¸ì”© ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n","        raw_corpus.extend(raw) # extend() : ë¦¬ìŠ¤íŠ¸í•¨ìˆ˜ë¡œ ì¶”ê°€ì ì¸ ë‚´ìš©ì„ ì—°ì¥ í•œë‹¤.\n","\n","print(\"ë°ì´í„° í¬ê¸°:\", len(raw_corpus))\n","print(\"Examples:\\n\", raw_corpus[:3])"],"metadata":{"id":"LqaQn1sXqwJI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765262307885,"user_tz":-540,"elapsed":581,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}},"outputId":"c7e24c0e-badc-4611-cc0c-9f47028a71dd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ë°ì´í„° í¬ê¸°: 187088\n","Examples:\n"," ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']\n"]}]},{"cell_type":"code","source":["import re\n","\n","def preprocess_sentence(sentence):\n","    sentence = sentence.lower().strip() # 1\n","    sentence = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", sentence) # 2\n","    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n","    sentence = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", sentence) # 4\n","    sentence = sentence.strip() # 5\n","    sentence = '<start> ' + sentence + ' <end>' # 6\n","    return sentence\n","\n","corpus = list(map(preprocess_sentence, raw_corpus))"],"metadata":{"id":"woGR2j_EuIhG","executionInfo":{"status":"ok","timestamp":1765262311764,"user_tz":-540,"elapsed":3835,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","\n","# í† í¬ë‚˜ì´ì € í•¨ìˆ˜ë¡œ Tensor ë³€í™˜\n","\n","def tokenize(corpus):\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","        num_words=12000,\n","        filters=' ',\n","        oov_token=\"<unk>\"\n","    )\n","\n","    tokenizer.fit_on_texts(corpus)\n","    tensor = tokenizer.texts_to_sequences(corpus)\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=15)\n","\n","    print(tensor,tokenizer)\n","    return tensor, tokenizer\n","\n","tensor, tokenizer = tokenize(corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKgooVEHtj6Q","executionInfo":{"status":"ok","timestamp":1765262327276,"user_tz":-540,"elapsed":15510,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}},"outputId":"547f4b2d-63df-47ae-d6e6-0eebccc80586"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[[  2 306  28 ...   0   0   0]\n"," [  2 221  13 ...   0   0   0]\n"," [  2  24  17 ...   0   0   0]\n"," ...\n"," [  2  23  77 ...   0   0   0]\n"," [  2  42  26 ...   0   0   0]\n"," [  2  23  77 ...   0   0   0]] <keras.src.legacy.preprocessing.text.Tokenizer object at 0x7a75ae11eb70>\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","enc_inputs = tensor[:, :-1]\n","dec_targets = tensor[:, 1:]\n","\n","# 20%ë¥¼ í‰ê°€ ë°ì´í„°ë¡œ ë¶„ë¦¬\n","enc_train, enc_val, dec_train, dec_val = train_test_split(\n","    enc_inputs,\n","    dec_targets,\n","    test_size=0.2,\n","    random_state=42,  # ì¬í˜„ì„± í™•ë³´ ìœ„í•´ ì‹œë“œ ê³ ì • (ì„ íƒ ì‚¬í•­)\n","    shuffle=True      # ë°ì´í„° ì„ê¸°\n",")"],"metadata":{"id":"NXXy2-JUuA7e","executionInfo":{"status":"ok","timestamp":1765262327373,"user_tz":-540,"elapsed":95,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["enc_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QuFFSK7lvsxO","executionInfo":{"status":"ok","timestamp":1765262327383,"user_tz":-540,"elapsed":4,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}},"outputId":"54689412-2639-42e1-c9a9-60c1f4fd9d74"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   4, 2118,    4, ...,  137,    4,  137],\n","       [   2, 1264,    4, ...,   42,  309,    3],\n","       [   2,   49,    4, ...,    0,    0,    0],\n","       ...,\n","       [   2,   39,    4, ...,    0,    0,    0],\n","       [   2,  163, 5658, ...,    0,    0,    0],\n","       [   2,    8,   72, ...,    0,    0,    0]], dtype=int32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["BUFFER_SIZE = len(enc_train)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(enc_train) // BATCH_SIZE\n","\n","VOCAB_SIZE = tokenizer.num_words + 1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","print(dataset)\n","\n","val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n","val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n","val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n","print(val_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Ayjde2JwNXS","executionInfo":{"status":"ok","timestamp":1765262327695,"user_tz":-540,"elapsed":311,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}},"outputId":"ccb1791a-03d7-44ee-9f9e-50bdd090ab1a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<_BatchDataset element_spec=(TensorSpec(shape=(64, 14), dtype=tf.int32, name=None), TensorSpec(shape=(64, 14), dtype=tf.int32, name=None))>\n","<_BatchDataset element_spec=(TensorSpec(shape=(64, 14), dtype=tf.int32, name=None), TensorSpec(shape=(64, 14), dtype=tf.int32, name=None))>\n"]}]},{"cell_type":"code","source":["class TextGenerator(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_size, hidden_size):\n","        super().__init__()\n","        # Embedding ë ˆì´ì–´, 2ê°œì˜ LSTM ë ˆì´ì–´, 1ê°œì˜ Dense ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.\n","        # Embedding ë ˆì´ì–´ëŠ” ë‹¨ì–´ ì‚¬ì „ì˜ ì¸ë±ìŠ¤ ê°’ì„ í•´ë‹¹ ì¸ë±ìŠ¤ ë²ˆì§¸ì˜ ì›Œë“œ ë²¡í„°ë¡œ ë°”ê¿”ì¤€ë‹¤.\n","        # ì´ ì›Œë“œ ë²¡í„°ëŠ” ì˜ë¯¸ ë²¡í„° ê³µê°„ì—ì„œ ë‹¨ì–´ì˜ ì¶”ìƒì  í‘œí˜„ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n","        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n","        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n","        self.linear = tf.keras.layers.Dense(vocab_size)\n","\n","    def call(self, x):\n","        out = self.embedding(x)\n","        out = self.rnn_1(out)\n","        out = self.rnn_2(out)\n","        out = self.linear(out)\n","\n","        return out\n","# embedding size ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ë‹¨ì–´ì˜ ì¶”ìƒì ì¸ íŠ¹ì§•ë“¤ì„ ë” ì¡ì•„ë‚¼ ìˆ˜ ìˆì§€ë§Œ\n","# ê·¸ë§Œí¼ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì•ˆì¢‹ì€ ê²°ê³¼ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤!\n","embedding_size = 256 # ì›Œë“œ ë²¡í„°ì˜ ì°¨ì›ìˆ˜ë¥¼ ë§í•˜ë©° ë‹¨ì–´ê°€ ì¶”ìƒì ìœ¼ë¡œ í‘œí˜„ë˜ëŠ” í¬ê¸°ì…ë‹ˆë‹¤.\n","hidden_size = 1024 # ëª¨ë¸ì— ì–¼ë§ˆë‚˜ ë§ì€ ì¼ê¾¼ì„ ë‘˜ ê²ƒì¸ê°€? ì •ë„ë¡œ ì´í•´í•˜ë©´ ì¢‹ë‹¤.\n","model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) # tokenizer.num_wordsì— +1ì¸ ì´ìœ ëŠ” ë¬¸ì¥ì— ì—†ëŠ” padê°€ ì‚¬ìš©ë˜ì—ˆê¸° ë•Œë¬¸ì´ë‹¤."],"metadata":{"id":"VeRVjDTXvrng","executionInfo":{"status":"ok","timestamp":1765262327719,"user_tz":-540,"elapsed":17,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam() # Adamì€ í˜„ì¬ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €ì´ë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì°¨ì°¨ ë°°ìš´ë‹¤.\n","loss = tf.keras.losses.SparseCategoricalCrossentropy( # í›ˆë ¨ ë°ì´í„°ì˜ ë¼ë²¨ì´ ì •ìˆ˜ì˜ í˜•íƒœë¡œ ì œê³µë  ë•Œ ì‚¬ìš©í•˜ëŠ” ì†ì‹¤í•¨ìˆ˜ì´ë‹¤.\n","    from_logits=True, # ê¸°ë³¸ê°’ì€ Falseì´ë‹¤. ëª¨ë¸ì— ì˜í•´ ìƒì„±ëœ ì¶œë ¥ ê°’ì´ ì •ê·œí™”ë˜ì§€ ì•Šì•˜ìŒì„ ì†ì‹¤ í•¨ìˆ˜ì— ì•Œë ¤ì¤€ë‹¤. ì¦‰ softmaxí•¨ìˆ˜ê°€ ì ìš©ë˜ì§€ ì•Šì•˜ë‹¤ëŠ”ê±¸ ì˜ë¯¸í•œë‹¤.\n","    reduction='none'  # ê¸°ë³¸ê°’ì€ SUMì´ë‹¤. ê°ì ë‚˜ì˜¤ëŠ” ê°’ì˜ ë°˜í™˜ ì›í•  ë•Œ Noneì„ ì‚¬ìš©í•œë‹¤.\n",")\n","# ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤í‚¤ ìœ„í•œ í•™ìŠµê³¼ì •ì„ ì„¤ì •í•˜ëŠ” ë‹¨ê³„ì´ë‹¤.\n","model.compile(loss=loss, optimizer=optimizer) # ì†ì‹¤í•¨ìˆ˜ì™€ í›ˆë ¨ê³¼ì •ì„ ì„¤ì •í–ˆë‹¤.\n","history = model.fit(\n","    dataset,\n","    validation_data=val_dataset,\n","    epochs=5\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"An0C1DkQwnwl","outputId":"699e0067-6e98-4dea-bfd3-e9d57deba38b","executionInfo":{"status":"ok","timestamp":1765264191447,"user_tz":-540,"elapsed":1863726,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m2338/2338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 158ms/step - loss: 3.4578 - val_loss: 2.8779\n","Epoch 2/5\n","\u001b[1m2338/2338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 158ms/step - loss: 2.7436 - val_loss: 2.6705\n","Epoch 3/5\n","\u001b[1m2338/2338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 159ms/step - loss: 2.4629 - val_loss: 2.5409\n","Epoch 4/5\n","\u001b[1m2338/2338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 159ms/step - loss: 2.2054 - val_loss: 2.4517\n","Epoch 5/5\n","\u001b[1m2338/2338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 159ms/step - loss: 1.9688 - val_loss: 2.4007\n"]}]},{"cell_type":"code","source":["def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20): #ì‹œì‘ ë¬¸ìì—´ì„ init_sentence ë¡œ ë°›ìœ¼ë©° ë””í´íŠ¸ê°’ì€ <start> ë¥¼ ë°›ëŠ”ë‹¤\n","    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œ ì…ë ¥ë°›ì€ init_sentenceë„ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤\n","    test_input = tokenizer.texts_to_sequences([init_sentence]) #í…ìŠ¤íŠ¸ ì•ˆì˜ ë‹¨ì–´ë“¤ì„ ìˆ«ìì˜ ì‹œí€€ìŠ¤ì˜ í˜•íƒœë¡œ ë³€í™˜\n","    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n","    end_token = tokenizer.word_index[\"<end>\"]\n","\n","    while True: #ë£¨í”„ë¥¼ ëŒë©´ì„œ init_sentenceì— ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ìƒì„±ì„±\n","        # 1\n","        predict = model(test_tensor)\n","        # 2\n","        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]\n","        # 3\n","        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n","        # 4\n","        if predict_word.numpy()[0] == end_token: break\n","        if test_tensor.shape[1] >= max_len: break\n","\n","    generated = \"\"\n","    # tokenizerë¥¼ ì´ìš©í•´ word indexë¥¼ ë‹¨ì–´ë¡œ í•˜ë‚˜ì”© ë³€í™˜í•©ë‹ˆë‹¤\n","    for word_index in test_tensor[0].numpy():\n","        generated += tokenizer.index_word[word_index] + \" \"\n","\n","    return generated #ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì´ ìƒì„±í•œ ë¬¸ì¥ì„ ë°˜í™˜"],"metadata":{"id":"aKUTvtlszBua","executionInfo":{"status":"ok","timestamp":1765264191458,"user_tz":-540,"elapsed":8,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["generate_text(model, tokenizer, init_sentence=\"<start> start \", max_len=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SaEbMlV502Q6","executionInfo":{"status":"ok","timestamp":1765266048045,"user_tz":-540,"elapsed":644,"user":{"displayName":"ë°•í˜•ì² ","userId":"15145739932293351945"}},"outputId":"d586588e-b898-4095-c1af-0b0ef51fdeea"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> start to get up to the sky <end> '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]}]}